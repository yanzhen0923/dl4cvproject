{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification with CNNs\n",
    "================\n",
    "\n",
    "The goal of this exercise is to implement a specific CNN architecture with PyTorch and train it on the CIFAR-10 image classification dataset. We will start by introducing the dataset and then implement a `nn.Module` and a useful `Solver` class. Seperating the model from the actual training has proven itself as a sensible design decision. By the end of this exercise you should have succesfully trained your (possible) first CNN model and have a boilerplate `Solver` class which you can reuse for the next exercise and your future research projects.\n",
    "\n",
    "For an inspiration on how to implement a model or the solver class you can have a look at [these](https://github.com/pytorch/examples) PyTorch examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from yz.data_utils_harddisk import get_Cancer_datasets\n",
    "from yz.solver import Solver\n",
    "from yz.data_utils_harddisk import get_balanced_weights\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_full_name = '~/dl4cvproject/data/train.csv'\n",
    "img_folder_full_name = '~/dl4cvproject/data/train256'\n",
    "csv_full_name = os.path.expanduser(csv_full_name)\n",
    "img_folder_full_name = os.path.expanduser(img_folder_full_name)\n",
    "\n",
    "csv_full_name_test = '~/dl4cvproject/data/test.csv'\n",
    "img_folder_full_name_test = '~/dl4cvproject/data/test256'\n",
    "csv_full_name_test = os.path.expanduser(csv_full_name_test)\n",
    "img_folder_full_name_test = os.path.expanduser(img_folder_full_name_test)\n",
    "\n",
    "#%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "#plt.rcParams['image.interpolation'] = 'nearest'\n",
    "#plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data, train_label_list = get_Cancer_datasets(csv_full_name=csv_full_name,img_folder_full_name=img_folder_full_name)\n",
    "test_X, csv_test = get_Cancer_datasets(csv_full_name=csv_full_name_test,img_folder_full_name=img_folder_full_name_test, mode='upload')\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))\n",
    "print(\"upload size: {}\".format(len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Cuda available')\n",
    "else:\n",
    "    print('Cuda not available :(---(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def target(factor, batch_size, lr_const, lr_exp, weight_decay_const, weight_decay_exp, num_epochs):\n",
    "\n",
    "    batch_size = int(batch_size)\n",
    "    num_epochs = int(num_epochs)\n",
    "    lr_const = int(lr_const)\n",
    "    weight_decay_const = int(weight_decay_const)\n",
    "    \n",
    "    #training\n",
    "    weights = get_balanced_weights(label_list=train_label_list, num_classes=14, factor=factor)\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, sampler=sampler, num_workers=8)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=20, shuffle=False, num_workers=8)\n",
    "    \n",
    "    model = models.resnet18(pretrained=True)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, 14)\n",
    "\n",
    "    lr = lr_const * np.power(10, lr_exp)\n",
    "    weigth_decay = weight_decay_const * np.power(10, weight_decay_exp)    \n",
    "    solver = Solver(optim_args={\"lr\":lr, \"weight_decay\":weigth_decay})\n",
    "    solver.train(model, train_loader, val_loader, log_nth=1, num_epochs=num_epochs)\n",
    "    \n",
    "    #compute local prediction acc\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=30, shuffle=False, num_workers=8)\n",
    "    scores = []\n",
    "    for inputs, target in tqdm(test_loader):\n",
    "        inputs, targets = Variable(inputs), Variable(target)\n",
    "        if torch.cuda.is_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        scores.extend((preds == targets).data.cpu().numpy())\n",
    "        \n",
    "    test_acc = np.mean(scores)\n",
    "    print(test_acc)\n",
    "    \n",
    "    ## generate submission file: submissions/res18_acc_randomsuffix.csv\n",
    "    if test_acc >= 0.01:\n",
    "        \n",
    "        file_name = 'submissions/res18_' + '{:.5f}'.format(test_acc) + '_' + ''.join(choice(ascii_uppercase) for i in range(7)) + '.csv'\n",
    "        print(file_name)\n",
    "        \n",
    "        try:\n",
    "            del csv_test['age']\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            del csv_test['gender']\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            del csv_test['view_position']\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            del csv_test['image_name']\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            del csv_test['detected']\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "        pred_set = set()\n",
    "        detected = []\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            tmp_pred_list = [0] * 14\n",
    "            inputs = test_X[i]\n",
    "            inputs = Variable(inputs.unsqueeze(0))\n",
    "            if torch.cuda.is_available:\n",
    "                inputs = inputs.cuda()\n",
    "            for trial in range(1):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                int_label = preds.data.cpu().numpy().tolist()[0]\n",
    "                tmp_pred_list[int_label] += 1\n",
    "\n",
    "            pred = tmp_pred_list.index(max(tmp_pred_list))\n",
    "            str_pred = 'class_' + str(pred + 1)\n",
    "            detected.append(str_pred)\n",
    "\n",
    "        csv_test['detected'] = pd.Series(detected)\n",
    "        csv_test.to_csv(file_name, index=False)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(target, {'factor':(0.5, 1), 'batch_size':(30, 80),\n",
    "                                   'lr_const':(1, 10), 'lr_exp':(-3, -7),\n",
    "                                   'weight_decay_const':(1, 10), 'weight_decay_exp':(-1, -6),\n",
    "                                   'num_epochs':(1, 7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bo.maximize(init_points=5, n_iter=100000, acq='ucb', kappa=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
