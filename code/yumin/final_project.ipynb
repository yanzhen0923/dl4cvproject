{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification with CNNs\n",
    "================\n",
    "\n",
    "The goal of this exercise is to implement a specific CNN architecture with PyTorch and train it on the CIFAR-10 image classification dataset. We will start by introducing the dataset and then implement a `nn.Module` and a useful `Solver` class. Seperating the model from the actual training has proven itself as a sensible design decision. By the end of this exercise you should have succesfully trained your (possible) first CNN model and have a boilerplate `Solver` class which you can reuse for the next exercise and your future research projects.\n",
    "\n",
    "For an inspiration on how to implement a model or the solver class you can have a look at [these](https://github.com/pytorch/examples) PyTorch examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "from data_utils import read_cancer_dataset\n",
    "from data_utils import data_augmentation\n",
    "from data_utils import norm_split_data\n",
    "from data_utils import devide_dataset_in_class_folders_and_duplicate_small_classes\n",
    "from data_utils import append_augmented_data\n",
    "\n",
    "\n",
    "csv_full_name = '/Users/yuminsun/dl4cvproject/data/train.csv'\n",
    "img_folder_full_name = '/Users/yuminsun/dl4cvproject/data/train256'\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancer Dataset\n",
    "=========\n",
    "\n",
    "Since the focus of this exercise should be neural network models and how to successfully train them, we provide you with preprocessed and prepared datasets. For an even easier management of the train, validation and test data pipelines we provide you with custom `torch.utils.data.Dataset` classes. Use the official [documentation](http://pytorch.org/docs/data.html) to make yourself familiar with the `Dataset` and `DataLoader` classes. Think about how you have to integrate them in your training loop and have a look at the data preprocessing steps in `dl4cv/data_utils.py`.\n",
    "\n",
    "The `num_workers` argument of the `DataLoader` class allows you to preprocess data with multiple threads.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>In this case we generated the `Dataset` classes after we applied all the preprocessing steps. Other datasets or random data augmentation might require an online preprocessing which can be integrated into the `Dataset` classes. See `torchvision.Transform` for examples.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 128/18577 [00:00<01:28, 208.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00010127.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 628/18577 [00:03<01:29, 200.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00010909.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1493/18577 [00:08<01:32, 184.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00012200.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 2103/18577 [00:11<01:32, 178.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00013156.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2668/18577 [00:16<01:39, 160.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00014013.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 2977/18577 [00:18<01:39, 157.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00014456.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 3058/18577 [00:19<01:40, 154.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00014562.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3150/18577 [00:21<01:42, 149.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00014710.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3384/18577 [00:23<01:46, 142.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00015073.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3751/18577 [00:26<01:45, 140.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00015624.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4423/18577 [00:32<01:44, 135.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00016637.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 4908/18577 [00:36<01:42, 133.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00017386.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5358/18577 [00:41<01:43, 127.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00018060.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5420/18577 [00:42<01:43, 126.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00018170.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 6010/18577 [00:47<01:38, 127.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00019058.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6094/18577 [00:48<01:38, 126.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00019183.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6150/18577 [00:48<01:38, 126.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00019278.png\n",
      "bad image  scan_00019285.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 6366/18577 [00:51<01:38, 124.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00019605.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 6399/18577 [00:51<01:38, 123.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00019651.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 6774/18577 [00:54<01:34, 124.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad image  scan_00020202.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7206/18577 [00:57<01:30, 125.14it/s]"
     ]
    }
   ],
   "source": [
    "data,class_statistics,class_fractions,img_name_list,bad_img_name_list = read_cancer_dataset(csv_full_name=csv_full_name,img_folder_full_name=img_folder_full_name)\n",
    "\n",
    "# print('store in local...')\n",
    "\n",
    "# with open('raw_data.pickle', 'wb') as f_raw:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(raw_data, f_raw, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# print('OK...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devide_dataset_in_class_folders_and_duplicate_small_classes(data,old_fractions,statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train,X_val,y_val,X_test,y_test = norm_split_data(aug_data)\n",
    "\n",
    "print('Store good, augment, norm, split data in local...')\n",
    "\n",
    "with open('data.pickle', 'wb') as f_final:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data, f_final, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('OK...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('aug_data.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     loaddata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Examples\n",
    "------------------\n",
    "\n",
    "To make yourself familiar with the dataset we visualize some examples. We show a few examples from each class. Note that we have to revert (transposition and mean subtraction) some preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aug_data = data_augmentation(data,fractions)\n",
    "\n",
    "# print('Store augment data in local...')\n",
    "\n",
    "# with open('aug_data.pickle', 'wb') as f_aug:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(aug_data, f_aug, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# print('OK...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Forward Pass \n",
    "\n",
    "After you understood the core concepts of PyTorch and have a rough idea on how to implement your own model, complete the initialization and forward methods of the `ClassificationCNN` in the `dl4cv/classifiers/classification_cnn.py` file. Note that we do not have to implement a backward pass since this is automatically handled by the `autograd` package.\n",
    "\n",
    "Use the cell below to check your results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation with the Solver\n",
    "We train and validate our previously generated model with a seperate `Solver` class defined in `dl4cv/solver.py`. Complete the `.train()` method and try to come up with an efficient iteration scheme as well as an informative training logger.\n",
    "\n",
    "Use the cells below to test your solver. A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>As seen below, the design of our `Solver` class is indepdenent of the particular model or data pipeline. This facilitates the reuse of the class and its modular structure allows the training of different models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Now train your model with the full dataset. By training a `ThreeLayerCNN` model for one epoch, you should already achieve greater than 40% accuracy on the validation set. If your training is painfully slow check if you did not forget to call the `nn.Module.cuda()` method.\n",
    "\n",
    "For the overfitting example we provided you with a set of hyperparamters (`hidden_dim`, `lr`, `weight_decay`, ...). You can start with the same parameter values but in order to maximize your accuracy you should try to train multiple models with different sets of hyperparamters. This process is called hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yz.classifiers.classification_cnn import ClassificationCNN\n",
    "from yz.classifiers.transferred_alexnet import alexnet\n",
    "from yz.solver import Solver\n",
    "from yz.data_utils import get_balanced_weights\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "weights = get_balanced_weights(train_label_list, 14)\n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=40, shuffle=False, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=40, shuffle=False, num_workers=8)\n",
    "\n",
    "model = alexnet(pretrained=True)\n",
    "#model.classifier  = nn.Sequential(\n",
    "#            nn.Linear(12544, 4096),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            nn.Linear(4096, 14),\n",
    "#)\n",
    "#model.classifier = nn.Sequential(\n",
    "#            nn.Linear(12544, 4096),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            nn.Linear(4096, 4096),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            nn.Linear(4096, 14)\n",
    "#)\n",
    "\n",
    "#list(model.classifier.children())[:-1] = nn.Linear(4096, 14)  \n",
    "#for param in model.features.parameters():\n",
    "#    param.requires_grad = False\n",
    "solver = Solver()\n",
    "solver.train(model, train_loader, val_loader, log_nth=1, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your Model\n",
    "Run your best model on the test set. You should easily achieve a score above 10% (random guessing for a classification task with 10 classes) accuracy on the given test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "scores = []\n",
    "for inputs, target in tqdm(test_loader):\n",
    "    #print(type(target))\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    #if model.is_cuda:\n",
    "    #    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    scores.extend((preds == targets).data.cpu().numpy())\n",
    "    \n",
    "print('Test set accuracy: %f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yz.data_utils import get_Cancer_datasets\n",
    "csv_full_name = '/home/hpc/pr92no/ga42cih2/Projects/dl4cvproject/data/test.csv'\n",
    "img_folder_full_name = '/home/hpc/pr92no/ga42cih2/Projects/dl4cvproject/data/test_400'\n",
    "test_X, csv_test = get_Cancer_datasets(csv_full_name=csv_full_name,img_folder_full_name=img_folder_full_name, mode='upload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = csv_test['detected'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(csv_test))\n",
    "print(test_X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del csv_test['age']\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    del csv_test['gender']\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    del csv_test['view_position']\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    del csv_test['image_name']\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    del csv_test['detected']\n",
    "except KeryError as e:\n",
    "    print(e)\n",
    "\n",
    "print(list(csv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = test_X[1000:1020]\n",
    "#if model.is_cuda:\n",
    "#        inputs = inputs.cuda()\n",
    "outputs = model(inputs)\n",
    "_, preds = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "index = 0\n",
    "jump = 30\n",
    "detected = []\n",
    "pred_set = set()\n",
    "for i in tqdm(range(int(test_X.size()[0] / jump) + 1)):\n",
    "    start = index\n",
    "    end = index + jump\n",
    "    if end >= (test_X.size()[0]) :\n",
    "        end = test_X.size()[0]\n",
    "    inputs = test_X[start:end]\n",
    "    # if model.is_cuda:\n",
    "    #     inputs = inputs.cuda()\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    ###\n",
    "    int_list_preds = preds.data.cpu().numpy().tolist()\n",
    "    for pred_num in int_list_preds:\n",
    "        pred_set.add(pred_num + 1)\n",
    "    str_list_preds = [('class_' + str(pred_num + 1)) for pred_num in int_list_preds]\n",
    "    detected.extend(str_list_preds)\n",
    "    ####\n",
    "    if end == test_X.size()[0]:\n",
    "        break\n",
    "    index += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred_set)\n",
    "csv_test['detected'] = pd.Series(detected)\n",
    "csv_test.to_csv('submission.csv', index=False)\n",
    "print(csv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.save(\"models/classification_cnn.model\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
